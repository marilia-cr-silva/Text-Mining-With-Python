{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "v1 Classifying_tweets_with_BERT.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I3XO86iKyh7Q"
      },
      "source": [
        "# Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nu9YCicx65Wg"
      },
      "source": [
        "# Libraries\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "!pip install ktrain\n",
        "import keras\n",
        "import ktrain\n",
        "from ktrain import text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wxfkD70vu1iK"
      },
      "source": [
        "# Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NxfHgzeN7fVu"
      },
      "source": [
        "# test dataset - tweets - the sentences are merged into a single tweet\n",
        "\n",
        "def dataframe_full_text(dataframe):\n",
        "  del dataframe['Unnamed: 0']\n",
        "  del dataframe['sentence']\n",
        "  lines, columns = dataframe.shape\n",
        "\n",
        "  if columns == 2:\n",
        "    df_final_test = dataframe\n",
        "    df_final_test.columns = ['sentence','target']\n",
        "\n",
        "  if columns > 2:\n",
        "    target = dataframe['target']\n",
        "    del dataframe['target']\n",
        "    lines, columns = dataframe.shape\n",
        "    array_test = np.array(dataframe)\n",
        "    array_empty = []\n",
        "    \n",
        "    for line in range(lines):\n",
        "      final_list = []\n",
        "      for column in range(0,columns-1,2):\n",
        "        string = str(array_test[line][column])\n",
        "        if string != '' and string != '??' and string != 'nan':\n",
        "          if '1.0' in string:\n",
        "            string = re.sub(r'1.0','1',string)\n",
        "          if '2.0' in string:\n",
        "            string = re.sub(r'2.0','2',string)\n",
        "          if '3.0' in string:\n",
        "            string = re.sub(r'3.0','3',string)\n",
        "          if '4.0' in string:\n",
        "            string = re.sub(r'4.0','4',string)\n",
        "          if '5.0' in string:\n",
        "            string = re.sub(r'5.0','5',string)\n",
        "          final_list.append(string)\n",
        "      final_string = ' '.join(final_list)\n",
        "      array_empty.append(final_string)\n",
        "\n",
        "    df_string_concat = pd.DataFrame(array_empty)\n",
        "    df_final_test = pd.concat((df_string_concat, target), axis = 1)\n",
        "    df_final_test.columns = ['sentence','target']\n",
        "\n",
        "  return df_final_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TMt1LvN4iTxR"
      },
      "source": [
        "# test dataset - sentences - the dataset comprises only sentences\n",
        "\n",
        "def dataframe_sentences(dataframe):\n",
        "  del dataframe['Unnamed: 0']\n",
        "  del dataframe['sentence']\n",
        "  lines, columns = dataframe.shape\n",
        "\n",
        "  if columns == 2:\n",
        "    df = dataframe\n",
        "\n",
        "  if columns > 2:\n",
        "    del dataframe['target']\n",
        "    lines, columns = dataframe.shape\n",
        "    array_test = np.array(dataframe)\n",
        "    sentence_target_list = []\n",
        "    \n",
        "    for line in range(lines):\n",
        "      for column in range(0,columns):\n",
        "        string = str(array_test[line][column])\n",
        "\n",
        "        if string != '' and string != '??' and string != 'nan' and string != 'NaN':\n",
        "          if ((len(sentence_target_list) != 0) and ((sentence_target_list[-1] == '1') or (sentence_target_list[-1] == '2') or (sentence_target_list[-1] == '3') or (sentence_target_list[-1] == '4') or (sentence_target_list[-1] == '5')) and ((string != '1') or (string != '2') or (string != '3') or (string != '4') or (string != '5'))):\n",
        "            if '1.0' in string:\n",
        "              string = re.sub(r'1.0','1',string)\n",
        "            if '2.0' in string:\n",
        "              string = re.sub(r'2.0','2',string)\n",
        "            if '3.0' in string:\n",
        "              string = re.sub(r'3.0','3',string)\n",
        "            if '4.0' in string:\n",
        "              string = re.sub(r'4.0','4',string)\n",
        "            if '5.0' in string:\n",
        "              string = re.sub(r'5.0','5',string)\n",
        "            sentence_target_list.append(string)\n",
        "          if ((len(sentence_target_list) != 0) and ((sentence_target_list[-1] != '1') or (sentence_target_list[-1] != '2') or (sentence_target_list[-1] != '3') or (sentence_target_list[-1] != '4') or (sentence_target_list[-1] != '5')) and ((string == '1') or (string == '2') or (string == '3') or (string == '4') or (string == '5'))):\n",
        "            if '1.0' in string:\n",
        "              string = re.sub(r'1.0','1',string)\n",
        "            if '2.0' in string:\n",
        "              string = re.sub(r'2.0','2',string)\n",
        "            if '3.0' in string:\n",
        "              string = re.sub(r'3.0','3',string)\n",
        "            if '4.0' in string:\n",
        "              string = re.sub(r'4.0','4',string)\n",
        "            if '5.0' in string:\n",
        "              string = re.sub(r'5.0','5',string)\n",
        "            sentence_target_list.append(string)\n",
        "          if len(sentence_target_list) == 0:\n",
        "            sentence_target_list.append(string)\n",
        "\n",
        "    length = len(sentence_target_list)\n",
        "    lines = int(length/2)\n",
        "    columns = 2\n",
        "    list_to_array = np.array(sentence_target_list)\n",
        "    final_array = np.reshape(list_to_array, (lines, columns))\n",
        "    df = pd.DataFrame(final_array)\n",
        "  df.columns = ['sentence','target']\n",
        "\n",
        "  return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-wwW_6wXeHzK"
      },
      "source": [
        "# classification - one-hot\n",
        "\n",
        "def one_hot(dataframe):\n",
        "  list_01 = [1,0,0,0,0]\n",
        "  list_02 = [0,1,0,0,0]\n",
        "  list_03 = [0,0,1,0,0]\n",
        "  list_04 = [0,0,0,1,0]\n",
        "  list_05 = [0,0,0,0,1]\n",
        "  lines, columns = dataframe.shape\n",
        "  df_array = np.array(dataframe)\n",
        "  one_hot_vectors = []\n",
        "\n",
        "  for i in range(lines):\n",
        "    if df_array[i][1] == 1 or df_array[i][1] == 1.0:\n",
        "      one_hot_vectors.append(list_01)\n",
        "    elif df_array[i][1] == 2 or df_array[i][1] == 2.0:\n",
        "      one_hot_vectors.append(list_02)\n",
        "    elif df_array[i][1] == 3 or df_array[i][1] == 3.0:\n",
        "      one_hot_vectors.append(list_03)\n",
        "    elif df_array[i][1] == 4 or df_array[i][1] == 4.0:\n",
        "      one_hot_vectors.append(list_04)\n",
        "    elif df_array[i][1] == 5 or df_array[i][1] == 5.0:\n",
        "      one_hot_vectors.append(list_05)\n",
        "\n",
        "  one_hot_array = np.array(one_hot_vectors).reshape(len(one_hot_vectors),5)\n",
        "  one_hot_dataframe = pd.DataFrame(one_hot_array)\n",
        "  del dataframe['target']\n",
        "  df_one_hot = pd.concat((dataframe,one_hot_dataframe), axis = 1)\n",
        "  df_one_hot.columns = ['sentence', '01','02','03','04','05']\n",
        "\n",
        "  return df_one_hot"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tWkA-7EEsnmC"
      },
      "source": [
        "# Loading files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9VyGUODFD9qw"
      },
      "source": [
        "# Loading files to dataframe\n",
        "\n",
        "# train dataset\n",
        "df_train = one_hot(dataframe_sentences(pd.read_excel('train_bert.xlsx')))\n",
        "\n",
        "# test dataset\n",
        "df_test_sentence = one_hot(dataframe_sentences(pd.read_excel('test_bert.xlsx')))\n",
        "df_test_tweet = one_hot(dataframe_full_text(pd.read_excel('test_bert.xlsx')))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KhEYYJc0KY8e"
      },
      "source": [
        "# Test 01"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4nqBcIKd-Vxu",
        "outputId": "4f3814c0-6f60-429b-b375-f98cc29a2948",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 806
        }
      },
      "source": [
        "# Create vectors https://github.com/amaiya/ktrain/blob/master/ktrain/text/data.py\n",
        "(x_train_00, y_train_00), (x_test_sentence, y_test_sentence), preproc = text.texts_from_df(df_train, text_column='sentence',\n",
        "                                                                                      label_columns=['01','02','03','04','05'],\n",
        "                                                                                      maxlen=64,\n",
        "                                                                                      preprocess_mode = 'bert',\n",
        "                                                                                      lang = None,\n",
        "                                                                                      ngram_range=1,\n",
        "                                                                                      val_df = df_test_sentence,\n",
        "                                                                                      random_state = 42\n",
        "                                                                                      )\n",
        "\n",
        "learn_bert_test_01 = ktrain.get_learner(text.text_classifier('bert', (x_train_00, y_train_00) , preproc=preproc), \n",
        "                             train_data=(x_train_00, y_train_00), \n",
        "                             val_data=(x_test_sentence, y_test_sentence), batch_size = 5\n",
        "                             )\n",
        "\n",
        "learn_bert_test_01.fit_onecycle(0.01,3)\n",
        "\n",
        "learn_bert_test_01.validate()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "downloading pretrained BERT model (multi_cased_L-12_H-768_A-12.zip)...\n",
            "[██████████████████████████████████████████████████]\n",
            "extracting pretrained BERT model...\n",
            "done.\n",
            "\n",
            "cleanup downloaded zip...\n",
            "done.\n",
            "\n",
            "preprocessing train...\n",
            "language: pt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "done."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Is Multi-Label? False\n",
            "preprocessing test...\n",
            "language: pt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "done."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Is Multi-Label? False\n",
            "maxlen is 64\n",
            "done.\n",
            "\n",
            "\n",
            "begin training using onecycle policy with max lr of 0.01...\n",
            "Epoch 1/3\n",
            "234/234 [==============================] - 1147s 5s/step - loss: 1.6864 - accuracy: 0.3316 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 2/3\n",
            "234/234 [==============================] - 1145s 5s/step - loss: 2.5595 - accuracy: 0.3538 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 3/3\n",
            "234/234 [==============================] - 1147s 5s/step - loss: 1.6179 - accuracy: 0.3265 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00     218.0\n",
            "           2       0.00      0.00      0.00       0.0\n",
            "\n",
            "    accuracy                           0.00     218.0\n",
            "   macro avg       0.00      0.00      0.00     218.0\n",
            "weighted avg       0.00      0.00      0.00     218.0\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  0, 218],\n",
              "       [  0,   0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l7a3jVqrjacw"
      },
      "source": [
        "# Test 02"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r5qEYhDELDCU",
        "outputId": "22dd6d50-e2b5-46f7-9ed0-8a45a686fd45",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 733
        }
      },
      "source": [
        "(x_train_01, y_train_01), (x_test_tweet, y_test_tweet), preproc01 = text.texts_from_df(df_train, text_column = 'sentence',\n",
        "                                                                                    label_columns = ['01','02','03','04','05'],\n",
        "                                                                                    maxlen = 64, \n",
        "                                                                                    preprocess_mode = 'bert',\n",
        "                                                                                    lang = None,\n",
        "                                                                                    ngram_range = 1,\n",
        "                                                                                    val_df = df_test_tweet,\n",
        "                                                                                    random_state = 42\n",
        "                                                                                    )\n",
        "\n",
        "learn_bert_test_02 = ktrain.get_learner(text.text_classifier('bert', (x_train_01, y_train_01) , preproc = preproc01), \n",
        "                             train_data = (x_train_01, y_train_01), \n",
        "                             val_data = (x_test_tweet, y_test_tweet), batch_size = 10\n",
        "                             )\n",
        "\n",
        "learn_bert_test_02.fit_onecycle(0.01,3)\n",
        "\n",
        "learn_bert_test_02.validate()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "preprocessing train...\n",
            "language: pt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "done."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Is Multi-Label? False\n",
            "preprocessing test...\n",
            "language: pt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "done."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Is Multi-Label? False\n",
            "maxlen is 64\n",
            "done.\n",
            "\n",
            "\n",
            "begin training using onecycle policy with max lr of 0.01...\n",
            "Epoch 1/3\n",
            "117/117 [==============================] - 961s 8s/step - loss: 1.6794 - accuracy: 0.3239 - val_loss: 2.7086 - val_accuracy: 0.0780\n",
            "Epoch 2/3\n",
            "117/117 [==============================] - 967s 8s/step - loss: 1.8557 - accuracy: 0.3316 - val_loss: 1.6847 - val_accuracy: 0.3670\n",
            "Epoch 3/3\n",
            "117/117 [==============================] - 956s 8s/step - loss: 1.4768 - accuracy: 0.3291 - val_loss: 1.5587 - val_accuracy: 0.0780\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         1\n",
            "           1       0.00      0.00      0.00        80\n",
            "           2       0.08      1.00      0.14        17\n",
            "           3       0.00      0.00      0.00        95\n",
            "           4       0.00      0.00      0.00        25\n",
            "\n",
            "    accuracy                           0.08       218\n",
            "   macro avg       0.02      0.20      0.03       218\n",
            "weighted avg       0.01      0.08      0.01       218\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0,  0,  1,  0,  0],\n",
              "       [ 0,  0, 80,  0,  0],\n",
              "       [ 0,  0, 17,  0,  0],\n",
              "       [ 0,  0, 95,  0,  0],\n",
              "       [ 0,  0, 25,  0,  0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U0BYq55rFuay"
      },
      "source": [
        "# Loading files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QJhgLKcqAtZW"
      },
      "source": [
        "# Loading files to dataframe\n",
        "\n",
        "# train dataset\n",
        "df_train = one_hot(dataframe_sentences(pd.read_excel('train_bag.xlsx')))\n",
        "\n",
        "# test dataset\n",
        "df_test_sentence = one_hot(dataframe_sentences(pd.read_excel('test_bag.xlsx')))\n",
        "df_test_tweet = one_hot(dataframe_full_text(pd.read_excel('test_bag.xlsx')))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0UFn-XfkA7dI"
      },
      "source": [
        "# Test 03"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KLwH2nPiBDnQ",
        "outputId": "03c758fe-f775-4b5c-96e3-86cafd2b55cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 806
        }
      },
      "source": [
        "# Create vectors https://github.com/amaiya/ktrain/blob/master/ktrain/text/data.py\n",
        "(x_train_00, y_train_00), (x_test_sentence, y_test_sentence), preproc = text.texts_from_df(df_train, text_column='sentence',\n",
        "                                                                                      label_columns=['01','02','03','04','05'],\n",
        "                                                                                      maxlen=64,\n",
        "                                                                                      preprocess_mode = 'bert',\n",
        "                                                                                      lang = None,\n",
        "                                                                                      ngram_range=1,\n",
        "                                                                                      val_df = df_test_sentence,\n",
        "                                                                                      random_state = 42,\n",
        "                                                                                      )\n",
        "\n",
        "learn_bert_test_01 = ktrain.get_learner(text.text_classifier('bert', (x_train_00, y_train_00) , preproc=preproc), \n",
        "                             train_data=(x_train_00, y_train_00), \n",
        "                             val_data=(x_test_sentence, y_test_sentence), batch_size = 5\n",
        "                             )\n",
        "\n",
        "learn_bert_test_01.fit_onecycle(0.01,3)\n",
        "\n",
        "learn_bert_test_01.validate()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "downloading pretrained BERT model (multi_cased_L-12_H-768_A-12.zip)...\n",
            "[██████████████████████████████████████████████████]\n",
            "extracting pretrained BERT model...\n",
            "done.\n",
            "\n",
            "cleanup downloaded zip...\n",
            "done.\n",
            "\n",
            "preprocessing train...\n",
            "language: pt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "done."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Is Multi-Label? False\n",
            "preprocessing test...\n",
            "language: pt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "done."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Is Multi-Label? False\n",
            "maxlen is 64\n",
            "done.\n",
            "\n",
            "\n",
            "begin training using onecycle policy with max lr of 0.01...\n",
            "Epoch 1/3\n",
            "234/234 [==============================] - 1157s 5s/step - loss: 2.0354 - accuracy: 0.3060 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 2/3\n",
            "234/234 [==============================] - 1148s 5s/step - loss: 2.5510 - accuracy: 0.3188 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 3/3\n",
            "234/234 [==============================] - 1146s 5s/step - loss: 1.6353 - accuracy: 0.3137 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00     218.0\n",
            "           2       0.00      0.00      0.00       0.0\n",
            "\n",
            "    accuracy                           0.00     218.0\n",
            "   macro avg       0.00      0.00      0.00     218.0\n",
            "weighted avg       0.00      0.00      0.00     218.0\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  0, 218],\n",
              "       [  0,   0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_kR4JsYtBIa4"
      },
      "source": [
        "# Test 04"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e-yo83EMBZVl",
        "outputId": "f3c11698-7377-4a22-84b6-6fbfb06579fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 733
        }
      },
      "source": [
        "(x_train_01, y_train_01), (x_test_tweet, y_test_tweet), preproc01 = text.texts_from_df(df_train, text_column = 'sentence',\n",
        "                                                                                    label_columns = ['01','02','03','04','05'],\n",
        "                                                                                    maxlen = 64, \n",
        "                                                                                    preprocess_mode = 'bert',\n",
        "                                                                                    lang = None,\n",
        "                                                                                    ngram_range = 1,\n",
        "                                                                                    val_df = df_test_tweet,\n",
        "                                                                                    random_state = 42\n",
        "                                                                                    )\n",
        "\n",
        "learn_bert_test_02 = ktrain.get_learner(text.text_classifier('bert', (x_train_01, y_train_01) , preproc = preproc01), \n",
        "                             train_data = (x_train_01, y_train_01), \n",
        "                             val_data = (x_test_tweet, y_test_tweet), batch_size = 10\n",
        "                             )\n",
        "\n",
        "learn_bert_test_02.fit_onecycle(0.01,3)\n",
        "\n",
        "learn_bert_test_02.validate()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "preprocessing train...\n",
            "language: pt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "done."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Is Multi-Label? False\n",
            "preprocessing test...\n",
            "language: pt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "done."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Is Multi-Label? False\n",
            "maxlen is 64\n",
            "done.\n",
            "\n",
            "\n",
            "begin training using onecycle policy with max lr of 0.01...\n",
            "Epoch 1/3\n",
            "117/117 [==============================] - 959s 8s/step - loss: 1.9373 - accuracy: 0.3205 - val_loss: 1.8341 - val_accuracy: 0.3670\n",
            "Epoch 2/3\n",
            "117/117 [==============================] - 952s 8s/step - loss: 1.9886 - accuracy: 0.3060 - val_loss: 3.2257 - val_accuracy: 0.4358\n",
            "Epoch 3/3\n",
            "117/117 [==============================] - 959s 8s/step - loss: 1.4113 - accuracy: 0.3419 - val_loss: 1.6079 - val_accuracy: 0.4358\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         1\n",
            "           1       0.00      0.00      0.00        80\n",
            "           2       0.00      0.00      0.00        17\n",
            "           3       0.44      1.00      0.61        95\n",
            "           4       0.00      0.00      0.00        25\n",
            "\n",
            "    accuracy                           0.44       218\n",
            "   macro avg       0.09      0.20      0.12       218\n",
            "weighted avg       0.19      0.44      0.26       218\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0,  0,  0,  1,  0],\n",
              "       [ 0,  0,  0, 80,  0],\n",
              "       [ 0,  0,  0, 17,  0],\n",
              "       [ 0,  0,  0, 95,  0],\n",
              "       [ 0,  0,  0, 25,  0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    }
  ]
}
