{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Corpus_unigrams_bigrams.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MJ16oZA8fvmD"
      },
      "source": [
        "# Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U_lkYHNufgXP"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from collections import Counter\n",
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pngUTxUhf0nf"
      },
      "source": [
        "# Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c_kvnQxKf3pQ"
      },
      "source": [
        "# the sentences are merged into a single tweet\n",
        "\n",
        "def dataframe_full_text(dataframe):\n",
        "  del dataframe['Unnamed: 0']\n",
        "  del dataframe['sentence']\n",
        "  lines, columns = dataframe.shape\n",
        "\n",
        "  if columns == 2:\n",
        "    df_final_test = dataframe\n",
        "    df_final_test.columns = ['sentence','target']\n",
        "\n",
        "  if columns > 2:\n",
        "    target = dataframe['target']\n",
        "    del dataframe['target']\n",
        "    lines, columns = dataframe.shape\n",
        "    array_test = np.array(dataframe)\n",
        "    array_empty = []\n",
        "    \n",
        "    for line in range(lines):\n",
        "      final_list = []\n",
        "      for column in range(0,columns-1,2):\n",
        "        string = str(array_test[line][column])\n",
        "        if string != '' and string != '??' and string != 'nan':\n",
        "          if '1.0' in string:\n",
        "            string = re.sub(r'1.0','1',string)\n",
        "          if '2.0' in string:\n",
        "            string = re.sub(r'2.0','2',string)\n",
        "          if '3.0' in string:\n",
        "            string = re.sub(r'3.0','3',string)\n",
        "          if '4.0' in string:\n",
        "            string = re.sub(r'4.0','4',string)\n",
        "          if '5.0' in string:\n",
        "            string = re.sub(r'5.0','5',string)\n",
        "          final_list.append(string)\n",
        "      final_string = ' '.join(final_list)\n",
        "      array_empty.append(final_string)\n",
        "\n",
        "    df_string_concat = pd.DataFrame(array_empty)\n",
        "    df_final_test = pd.concat((df_string_concat, target), axis = 1)\n",
        "    df_final_test.columns = ['sentence','target']\n",
        "\n",
        "  return df_final_test"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g5I3qqBsf66Z"
      },
      "source": [
        "# test dataset - sentences - the dataset comprises only sentences\n",
        "\n",
        "def dataframe_sentences(dataframe):\n",
        "  del dataframe['Unnamed: 0']\n",
        "  del dataframe['sentence']\n",
        "  lines, columns = dataframe.shape\n",
        "\n",
        "  if columns == 2:\n",
        "    df = dataframe\n",
        "\n",
        "  if columns > 2:\n",
        "    del dataframe['target']\n",
        "    lines, columns = dataframe.shape\n",
        "    array_test = np.array(dataframe)\n",
        "    sentence_target_list = []\n",
        "    \n",
        "    for line in range(lines):\n",
        "      for column in range(0,columns):\n",
        "        string = str(array_test[line][column])\n",
        "\n",
        "        if string != '' and string != '??' and string != 'nan' and string != 'NaN':\n",
        "          if ((len(sentence_target_list) != 0) and ((sentence_target_list[-1] == '1') or (sentence_target_list[-1] == '2') or (sentence_target_list[-1] == '3') or (sentence_target_list[-1] == '4') or (sentence_target_list[-1] == '5')) and ((string != '1') or (string != '2') or (string != '3') or (string != '4') or (string != '5'))):\n",
        "            if '1.0' in string:\n",
        "              string = re.sub(r'1.0','1',string)\n",
        "            if '2.0' in string:\n",
        "              string = re.sub(r'2.0','2',string)\n",
        "            if '3.0' in string:\n",
        "              string = re.sub(r'3.0','3',string)\n",
        "            if '4.0' in string:\n",
        "              string = re.sub(r'4.0','4',string)\n",
        "            if '5.0' in string:\n",
        "              string = re.sub(r'5.0','5',string)\n",
        "            sentence_target_list.append(string)\n",
        "          if ((len(sentence_target_list) != 0) and ((sentence_target_list[-1] != '1') or (sentence_target_list[-1] != '2') or (sentence_target_list[-1] != '3') or (sentence_target_list[-1] != '4') or (sentence_target_list[-1] != '5')) and ((string == '1') or (string == '2') or (string == '3') or (string == '4') or (string == '5'))):\n",
        "            if '1.0' in string:\n",
        "              string = re.sub(r'1.0','1',string)\n",
        "            if '2.0' in string:\n",
        "              string = re.sub(r'2.0','2',string)\n",
        "            if '3.0' in string:\n",
        "              string = re.sub(r'3.0','3',string)\n",
        "            if '4.0' in string:\n",
        "              string = re.sub(r'4.0','4',string)\n",
        "            if '5.0' in string:\n",
        "              string = re.sub(r'5.0','5',string)\n",
        "            sentence_target_list.append(string)\n",
        "          if len(sentence_target_list) == 0:\n",
        "            sentence_target_list.append(string)\n",
        "\n",
        "    length = len(sentence_target_list)\n",
        "    lines = int(length/2)\n",
        "    columns = 2\n",
        "    list_to_array = np.array(sentence_target_list)\n",
        "    final_array = np.reshape(list_to_array, (lines, columns))\n",
        "    df = pd.DataFrame(final_array)\n",
        "  df.columns = ['sentence','target']\n",
        "\n",
        "  return df"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "meINyTrZgBi2"
      },
      "source": [
        "# corpus - unigrams and bigrams\n",
        "\n",
        "def get_corpus_tokens(dataframe): # train set\n",
        "  sentences = dataframe['sentence']\n",
        "  array_sentences = np.array(sentences)\n",
        "  length = len(array_sentences)\n",
        "  string_list = []\n",
        "\n",
        "  for i in range(length):\n",
        "    string = str(array_sentences[i])\n",
        "    string_list.append(string)\n",
        "  corpus_list = ' '.join(string_list)\n",
        "  corpus_tokens = nltk.word_tokenize(corpus_list)\n",
        "  frequency = nltk.FreqDist(corpus_tokens)\n",
        "  all_frequencies = frequency.most_common()\n",
        "  array_zipf = np.array(all_frequencies)\n",
        "  dataframe_zipf = pd.DataFrame(array_zipf)\n",
        "\n",
        "  bigrams = zip(corpus_tokens, corpus_tokens[1:])\n",
        "  counts = Counter(bigrams)\n",
        "  list_bigrams = counts.most_common()\n",
        "\n",
        "  return dataframe_zipf, list_bigrams"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sNmYaulUg28F"
      },
      "source": [
        "# split dataframe into classes\n",
        "\n",
        "def split_dataframe(dataframe): # train set\n",
        "  array_sentences = np.array(dataframe)\n",
        "  length = len(array_sentences)\n",
        "  list_01 = []\n",
        "  list_02 = []\n",
        "  list_03 = []\n",
        "  list_04 = []\n",
        "  list_05 = []\n",
        "\n",
        "  for i in range(length):\n",
        "    if array_sentences[i][1] == 1:\n",
        "      list_01.append(array_sentences[i][0])\n",
        "      list_01.append(array_sentences[i][1])\n",
        "    elif array_sentences[i][1] == 2:\n",
        "      list_02.append(array_sentences[i][0])\n",
        "      list_02.append(array_sentences[i][1])\n",
        "    elif array_sentences[i][1] == 3:\n",
        "      list_03.append(array_sentences[i][0])\n",
        "      list_03.append(array_sentences[i][1])\n",
        "    elif array_sentences[i][1] == 4:\n",
        "      list_04.append(array_sentences[i][0])\n",
        "      list_04.append(array_sentences[i][1])\n",
        "    elif array_sentences[i][1] == 5:\n",
        "      list_05.append(array_sentences[i][0])\n",
        "      list_05.append(array_sentences[i][1])\n",
        "\n",
        "  # list_01 to dataframe\n",
        "  length = len(list_01)\n",
        "  lines = int(length/2)\n",
        "  columns = 2\n",
        "  dataframe_01 = pd.DataFrame(np.reshape((np.array(list_01)), (lines, columns)))\n",
        "  dataframe_01.columns = ['sentence','target']\n",
        "\n",
        "  # list_02 to dataframe\n",
        "  length = len(list_02)\n",
        "  lines = int(length/2)\n",
        "  columns = 2\n",
        "  dataframe_02 = pd.DataFrame(np.reshape((np.array(list_02)), (lines, columns)))\n",
        "  dataframe_02.columns = ['sentence','target']\n",
        "\n",
        "  # list_03 to dataframe\n",
        "  length = len(list_03)\n",
        "  lines = int(length/2)\n",
        "  columns = 2\n",
        "  dataframe_03 = pd.DataFrame(np.reshape((np.array(list_03)), (lines, columns)))\n",
        "  dataframe_03.columns = ['sentence','target']\n",
        "\n",
        "  # list_04 to dataframe\n",
        "  length = len(list_04)\n",
        "  lines = int(length/2)\n",
        "  columns = 2\n",
        "  dataframe_04 = pd.DataFrame(np.reshape((np.array(list_04)), (lines, columns)))\n",
        "  dataframe_04.columns = ['sentence','target']\n",
        "\n",
        "  # list_05 to dataframe\n",
        "  length = len(list_05)\n",
        "  lines = int(length/2)\n",
        "  columns = 2\n",
        "  dataframe_05 = pd.DataFrame(np.reshape((np.array(list_05)), (lines, columns)))\n",
        "  dataframe_05.columns = ['sentence','target']\n",
        "\n",
        "  return dataframe_01, dataframe_02, dataframe_03, dataframe_04, dataframe_05"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WeHCuBV3gVEO"
      },
      "source": [
        "# Loading files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "14ztoaOs2n02"
      },
      "source": [
        "# Loading files to dataframe\n",
        "\n",
        "corpus_train_bag, bigrams_train_bag = get_corpus_tokens(dataframe_sentences(pd.read_excel('train_bag.xlsx')))\n",
        "corpus_train_bag_stemmer, bigrams_train_bag_stemmer = get_corpus_tokens(dataframe_sentences(pd.read_excel('train_bag_stemmer.xlsx')))\n",
        "corpus_train_bert, bigrams_train_bert = get_corpus_tokens(dataframe_sentences(pd.read_excel('train_bert.xlsx')))"
      ],
      "execution_count": 58,
      "outputs": []
    }
  ]
}